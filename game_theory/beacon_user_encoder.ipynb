{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch._C.Generator object at 0x7ff7b1daf4b0>"
     ]
    }
   ],
   "source": [
    "# Let's SEEED ! yay\n",
    "seed =2024\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "mainPath = \"./data\"\n",
    "\n",
    "num_epochs = 100\n",
    "honesty_weight = 1.0  # Adjust as necessary\n",
    "sequencing_error = 0.001\n",
    "beacon_LR = 0.001\n",
    "attacker_LR = 0.001\n",
    "\n",
    "#TODO: change the sizes\n",
    "beacon_input_size = 5  # we go with 5 queries\n",
    "beacon_hidden_size = 10\n",
    "beacon_output_size = 1  # Single otput (between 0 and 1)\n",
    "\n",
    "attacker_input_size = 5\n",
    "attacker_hidden_size = 10\n",
    "attacker_output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Â CEU Beacon - it contains 164 people in total which we will divide into groups to experiment\n",
    "beacon = pd.read_csv(os.path.join(mainPath, \"Beacon_164.txt\"), index_col=0, delim_whitespace=True)\n",
    "\n",
    "# Reference genome, i.e. the genome that has no SNPs, all major allele pairs for each position\n",
    "reference = pickle.load(open(os.path.join(mainPath, \"reference.pickle\"),\"rb\"))\n",
    "\n",
    "# Binary representation of the beacon; 0: no SNP (i.e. no mutation) 1: SNP (i.e. mutation)\n",
    "binary = np.logical_and(beacon.values != reference, beacon.values != \"NN\").astype(int) \n",
    "\n",
    "# Table that contains MAF (minor allele frequency) values for each position. \n",
    "maf = pd.read_csv(os.path.join(mainPath, \"MAF.txt\"), index_col=0, delim_whitespace=True)\n",
    "maf.rename(columns = {'referenceAllele':'major', 'referenceAlleleFrequency':'major_freq', \n",
    "                      'otherAllele':'minor', 'otherAlleleFrequency':'minor_freq'}, inplace = True)\n",
    "maf[\"maf\"] = np.round(maf[\"maf\"].values, 3)\n",
    "\n",
    "\n",
    "# Same variable with sorted maf values\n",
    "sorted_maf = maf.sort_values(by='maf')\n",
    "\n",
    "# Extracting column to an array for future use\n",
    "maf_values = maf[\"maf\"].values\n",
    "\n",
    "# Prepare index arrays for future use\n",
    "# beacon_people = np.arange(65)\n",
    "# other_people = np.arange(99)+65\n",
    "all_people = np.arange(164)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# MAF values are calculated from a small subset they might be 0. \n",
    "# This does not mean they are not seen in anybody in the world so we are replacing 0 MAF values with 0.001 which is a pretty rare value\n",
    "maf[\"maf\"] = maf[\"maf\"].apply(lambda x: 0.001 if x == 0 else x)\n",
    "maf_values = maf[\"maf\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "shuffled = np.random.permutation(all_people)\n",
    "\n",
    "test_int = shuffled[:60]\n",
    "train_ind = shuffled[60:164]\n",
    "\n",
    "beacon_val = binary[:, test_int]\n",
    "beacon_train = binary[:, train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "maf_categories = np.zeros_like(maf_values, dtype=np.ubyte)\n",
    "\n",
    "for i, maf in enumerate(maf_values):\n",
    "    if maf < .03:\n",
    "        maf_categories[i] = 0\n",
    "    elif maf < 0.1:\n",
    "        maf_categories[i] = 1\n",
    "    elif maf < 0.2:\n",
    "        maf_categories[i] = 2\n",
    "    elif maf < 0.3:\n",
    "        maf_categories[i] = 3\n",
    "    elif maf < 0.4:\n",
    "        maf_categories[i] = 4\n",
    "    else:\n",
    "        maf_categories[i] = 5\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 4029840)\n",
      "(104, 4029840)\n"
     ]
    }
   ],
   "source": [
    "print(beacon_val.T.shape)\n",
    "print(beacon_train.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, conv_output_size, fc1_output_size, fc2_output_size, fc3_output_size):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        self.conv1x1 = nn.Conv1d(3, 1, kernel_size=6, stride=3)\n",
    "        self.fc1 = nn.Linear(conv_output_size, fc1_output_size)\n",
    "        # self.fc2 = nn.Linear(fc1_output_size, fc2_output_size)\n",
    "        self.fc3 = nn.Linear(fc1_output_size, fc3_output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1x1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class UserDecoder(nn.Module):\n",
    "    def __init__(self, fc3_output_size, fc2_output_size, fc1_output_size, conv_output_size):\n",
    "        super(UserDecoder, self).__init__()\n",
    "        self.fc3 = nn.Linear(fc3_output_size, fc2_output_size)\n",
    "        # self.fc2 = nn.Linear(fc2_output_size, fc1_output_size)\n",
    "        self.fc1 = nn.Linear(fc2_output_size, conv_output_size)\n",
    "        self.conv1x1 = nn.ConvTranspose1d(1, 3, kernel_size=6, stride=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = x.view(x.size(0), 1, -1)\n",
    "        x = self.conv1x1(x)\n",
    "        return x\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded.to(torch.device(\"cuda:1\")))\n",
    "        return decoded.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xonsh: For full traceback set: $XONSH_SHOW_TRACEBACK = True\n",
      "AttributeError: module 'torch.utils' has no attribute 'data'\n"
     ]
    }
   ],
   "source": [
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(DummyDataset, self).__init__()\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.stack((self.data[idx, :], maf_values, maf_categories))\n",
    "        # return self.data[idx, :]\n",
    "\n",
    "# Hyperparameters\n",
    "conv_output_size = 1343279\n",
    "fc1_output_size = 400\n",
    "fc2_output_size = 32\n",
    "fc3_output_size = 3\n",
    "learning_rate = 0.0005\n",
    "num_epochs = 80\n",
    "batch_size = 1\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23987748864, 25388515328)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# del user_encoder\n",
    "# del user_decoder\n",
    "# del autoencoder\n",
    "# del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize UserEncoder and UserDecoder\n",
    "user_encoder = UserEncoder(conv_output_size, fc1_output_size, fc2_output_size, fc3_output_size).to(torch.device(\"cuda:0\"))\n",
    "user_decoder = UserDecoder(fc3_output_size, fc2_output_size, fc1_output_size, conv_output_size).to(torch.device(\"cuda:1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create AutoEncoder\n",
    "autoencoder = AutoEncoder(user_encoder, user_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, outputs, targets):\n",
    "        mae_loss = F.l1_loss(outputs, targets, reduction='mean')\n",
    "        mse_loss = F.mse_loss(outputs, targets, reduction='mean')\n",
    "        return mae_loss + mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = CustomLoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train_dataset = DummyDataset(beacon_train.T)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = DummyDataset(beacon_val.T)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Train Loss: 1.6796, Val Loss: 1.6631\n",
      "Epoch [2/80], Train Loss: 1.6353, Val Loss: 1.6168\n",
      "Epoch [3/80], Train Loss: 1.5918, Val Loss: 1.5754\n",
      "Epoch [4/80], Train Loss: 1.5510, Val Loss: 1.5372\n",
      "Epoch [5/80], Train Loss: 1.5141, Val Loss: 1.5035\n",
      "Epoch [6/80], Train Loss: 1.4808, Val Loss: 1.4711\n",
      "Epoch [7/80], Train Loss: 1.4529, Val Loss: 1.4466\n",
      "Epoch [8/80], Train Loss: 1.4300, Val Loss: 1.4249\n",
      "Epoch [9/80], Train Loss: 1.4116, Val Loss: 1.4091\n",
      "Epoch [10/80], Train Loss: 1.3978, Val Loss: 1.3967\n",
      "Epoch [11/80], Train Loss: 1.3866, Val Loss: 1.3872\n",
      "Epoch [12/80], Train Loss: 1.3784, Val Loss: 1.3796\n",
      "Epoch [13/80], Train Loss: 1.3715, Val Loss: 1.3741\n",
      "Epoch [14/80], Train Loss: 1.3664, Val Loss: 1.3697\n",
      "Epoch [15/80], Train Loss: 1.3627, Val Loss: 1.3665\n",
      "Epoch [16/80], Train Loss: 1.3600, Val Loss: 1.3650\n",
      "Epoch [17/80], Train Loss: 1.3587, Val Loss: 1.3659\n",
      "Epoch [18/80], Train Loss: 1.3580, Val Loss: 1.3643\n",
      "Epoch [19/80], Train Loss: 1.3571, Val Loss: 1.3637\n",
      "Epoch [20/80], Train Loss: 1.3566, Val Loss: 1.3618\n",
      "Epoch [21/80], Train Loss: 1.3560, Val Loss: 1.3611\n",
      "Epoch [22/80], Train Loss: 1.3557, Val Loss: 1.3606\n",
      "Epoch [23/80], Train Loss: 1.3547, Val Loss: 1.3608\n",
      "Epoch [24/80], Train Loss: 1.3544, Val Loss: 1.3599\n",
      "Epoch [25/80], Train Loss: 1.3543, Val Loss: 1.3593\n",
      "Epoch [26/80], Train Loss: 1.3536, Val Loss: 1.3593\n",
      "Epoch [27/80], Train Loss: 1.3534, Val Loss: 1.3589\n",
      "Epoch [28/80], Train Loss: 1.3824, Val Loss: 1.3676\n",
      "Epoch [29/80], Train Loss: 1.3608, Val Loss: 1.3591\n",
      "Epoch [30/80], Train Loss: 1.3562, Val Loss: 1.3600\n",
      "Epoch [31/80], Train Loss: 1.3518, Val Loss: 1.3577\n",
      "Epoch [32/80], Train Loss: 1.3507, Val Loss: 1.3554\n",
      "Epoch [33/80], Train Loss: 1.3494, Val Loss: 1.3543\n",
      "Epoch [34/80], Train Loss: 1.3487, Val Loss: 1.3542\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device).float()\n",
    "        outputs = autoencoder(data)\n",
    "        loss = criterion(outputs, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    autoencoder.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            data = data.to(device).float()\n",
    "            outputs = autoencoder(data)\n",
    "            loss = criterion(outputs, data)\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss# Save the pretrained encoder\n",
    "        torch.save(user_encoder.state_dict(), 'user_encoder.pth')\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the losses\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xonsh",
   "language": "xonsh",
   "name": "xonsh"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".xsh",
   "mimetype": "text/x-sh",
   "name": "xonsh",
   "pygments_lexer": "xonsh",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
