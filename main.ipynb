{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:28:08.939274Z",
     "start_time": "2024-05-15T07:28:08.788731Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:28:09.945440Z",
     "start_time": "2024-05-15T07:28:09.921545Z"
    }
   },
   "outputs": [],
   "source": [
    "def reproducibility(seed: int):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "reproducibility(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:28:09.984903Z",
     "start_time": "2024-05-15T07:28:09.946374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to : NVIDIA TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:28:27.555430Z",
     "start_time": "2024-05-15T07:28:27.497144Z"
    }
   },
   "outputs": [],
   "source": [
    "def args_create():\n",
    "    # @title Arguments\n",
    "    parser = argparse.ArgumentParser(description='Actor Critic')\n",
    "\n",
    "\n",
    "    # Environment Setup\n",
    "    parser.add_argument('--data', default=\"/mnt/kerem/CEU\", type=str, help='Dataset Path')\n",
    "    parser.add_argument('--episodes', default=7000, type=int, metavar='N', help='Number of episodes for training agent.')\n",
    "    parser.add_argument('--seed', default=3, type=int, help='Seed for reproducibility')\n",
    "    parser.add_argument('--a_control_size', default=50, type=int, help='Attack Control group size')\n",
    "    parser.add_argument('--b_control_size', default=50, type=int, help='Beacon Control group size')\n",
    "    parser.add_argument('--gene_size', default=100, type=int, help='States gene size')\n",
    "    parser.add_argument('--beacon_size', default=10, type=int, help='Beacon population size')\n",
    "    parser.add_argument('--victim_prob', default=1, type=float, help='Victim inside beacon or not!')\n",
    "    parser.add_argument('--max_queries', default=5, type=int, help='Maximum queries per episode')\n",
    "    parser.add_argument('--evaluate', default=False, type=bool, help='Evaluation or Not')\n",
    "\n",
    "\n",
    "    # Training Setup\n",
    "    parser.add_argument('--train', default=\"beacon\", choices=[\"attacker\", \"beacon\", \"both\"], type=str, help='Train side!')\n",
    "    \n",
    "    parser.add_argument('--attacker_type', default=\"optimal\", choices=[\"random\", \"optimal\", \"agent\"], type=str, help='Type of the attacker')\n",
    "    parser.add_argument('--beacon_type', default=\"agent\", choices=[\"random\", \"agent\", \"truth\"], type=str, help='Type of the beacon')\n",
    "\n",
    "    parser.add_argument('--beacon_agent', default=\"td\", choices=[\"td\", \"ppo\"], type=str, help='Type of the beacon')\n",
    "\n",
    "    parser.add_argument('--pop_reset_freq', default=100000000, type=int, help='Reset Population Frequency (Epochs)')\n",
    "    parser.add_argument('--update_freq', default=10, type=int, help='Train Agent model frequency')\n",
    "    parser.add_argument('--plot-freq', default=10, type=int, metavar='N', help='Plot Frequencies')\n",
    "\n",
    "    parser.add_argument('--resume-attacker', default=None, type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('--resume-beacon', default=None, type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n",
    "\n",
    "\n",
    "    parser.add_argument('--results-dir', default='./results/train', type=str, metavar='PATH', help='path to cache (default: none)')\n",
    "\n",
    "    # args = parser.parse_args()  # running in command line\n",
    "    args = parser.parse_args('')  # running in ipynb\n",
    "\n",
    "    args.results_dir = os.path.join(args.results_dir, \"run\"+str(len(os.listdir(args.results_dir))))\n",
    "    os.makedirs(args.results_dir)\n",
    "    os.makedirs(args.results_dir+\"/logs\")\n",
    "    os.makedirs(args.results_dir+\"/rewards\")\n",
    "    os.makedirs(args.results_dir+\"/indrewards\")\n",
    "    os.makedirs(args.results_dir+\"/actions\")\n",
    "    os.makedirs(args.results_dir+\"/pvalues\")\n",
    "\n",
    "    args.device = device\n",
    "\n",
    "    print(args)\n",
    "    return args\n",
    "\n",
    "# args = args_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:29:52.958822Z",
     "start_time": "2024-05-15T07:28:30.551222Z"
    }
   },
   "outputs": [],
   "source": [
    "# CEU Beacon - it contains 164 people in total which we will divide into groups to experiment\n",
    "beacon = pd.read_csv(os.path.join(\"/mnt/kerem/CEU\", \"Beacon_164.txt\"), index_col=0, delim_whitespace=True)\n",
    "# Reference genome, i.e. the genome that has no SNPs, all major allele pairs for each position\n",
    "reference = pickle.load(open(os.path.join(\"/mnt/kerem/CEU\", \"reference.pickle\"),\"rb\"))\n",
    "# Binary representation of the beacon; 0: no SNP (i.e. no mutation) 1: SNP (i.e. mutation)\n",
    "binary = np.logical_and(beacon.values != reference, beacon.values != \"NN\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:29:57.981450Z",
     "start_time": "2024-05-15T07:29:52.960426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 4029840)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table that contains MAF (minor allele frequency) values for each position. \n",
    "maf = pd.read_csv(os.path.join(\"/mnt/kerem/CEU\", \"MAF.txt\"), index_col=0, delim_whitespace=True)\n",
    "maf.rename(columns = {'referenceAllele':'major', 'referenceAlleleFrequency':'major_freq', \n",
    "                      'otherAllele':'minor', 'otherAlleleFrequency':'minor_freq'}, inplace = True)\n",
    "maf[\"maf\"] = np.round(maf[\"maf\"].values, 3)\n",
    "# Same variable with sorted maf values\n",
    "sorted_maf = maf.sort_values(by='maf')\n",
    "# Extracting column to an array for future use\n",
    "maf_values = maf[\"maf\"].values\n",
    "\n",
    "binary = binary.T\n",
    "binary.shape #(164, 4029840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:29:58.020758Z",
     "start_time": "2024-05-15T07:29:57.981165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4029840, 164), (4029840, 1), (164, 4029840), (4029840,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beacon.shape, reference.shape, binary.shape, maf_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:30:03.513711Z",
     "start_time": "2024-05-15T07:29:58.005673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469106, 752922.737804878, 1030061)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.sum(binary, axis=1)), np.mean(np.sum(binary, axis=1)), np.max(np.sum(binary, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15236833621185972, 0.5, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(maf_values), np.max(maf_values), np.min(maf_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T07:30:05.016683Z",
     "start_time": "2024-05-15T07:30:03.553232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Namespace(data='/mnt/kerem/CEU', episodes=7000, seed=3, a_control_size=50, b_control_size=50, gene_size=100, beacon_size=10, victim_prob=1, max_queries=5, evaluate=False, train='beacon', attacker_type='optimal', beacon_type='agent', beacon_agent='td', pop_reset_freq=100000000, update_freq=10, plot_freq=10, resume_attacker=None, resume_beacon=None, results_dir='./results/train/run5', device=device(type='cuda', index=0))\n",
      "./results/train/run5/logs/beacon_log.csv\n",
      "./results/train/run5/logs/beacon_control_log.csv\n",
      "./results/train/run5/logs/attacker_log.csv\n",
      "./results/train/run5/logs/attacker_control_log.csv\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 1⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2024-07-15 21:00:44\n",
      "============================================================================================\n",
      "current logging run number for  :  0\n",
      "save checkpoint path : ./results/train/run5/weights/PPO_0.pth\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 5 \t Beacon Reward : tensor([7.8441])\t Attacker Reward : tensor([-2.1559])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 2⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 10 \t Beacon Reward : tensor([8.1861])\t Attacker Reward : tensor([-1.8139])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 3⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 15 \t Beacon Reward : tensor([7.8857])\t Attacker Reward : tensor([-2.1143])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 4⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 20 \t Beacon Reward : tensor([7.6364])\t Attacker Reward : tensor([-2.3636])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 5⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 25 \t Beacon Reward : tensor([7.8772])\t Attacker Reward : tensor([-2.1228])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 6⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 30 \t Beacon Reward : tensor([7.8422])\t Attacker Reward : tensor([-2.1578])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 7⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 35 \t Beacon Reward : tensor([7.6335])\t Attacker Reward : tensor([-2.3665])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 8⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 40 \t Beacon Reward : tensor([7.6201])\t Attacker Reward : tensor([-2.3799])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 9⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 45 \t Beacon Reward : tensor([7.7234])\t Attacker Reward : tensor([-2.2766])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 10⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 50 \t Beacon Reward : tensor([7.7509])\t Attacker Reward : tensor([-2.2491])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:13\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 11⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 55 \t Beacon Reward : tensor([5.5857])\t Attacker Reward : tensor([-4.4143])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 12⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 60 \t Beacon Reward : tensor([5.8505])\t Attacker Reward : tensor([-4.1495])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 13⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 65 \t Beacon Reward : tensor([5.5228])\t Attacker Reward : tensor([-4.4772])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 14⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 70 \t Beacon Reward : tensor([5.5860])\t Attacker Reward : tensor([-4.4140])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 15⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 75 \t Beacon Reward : tensor([5.6328])\t Attacker Reward : tensor([-4.3672])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 16⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 80 \t Beacon Reward : tensor([5.5486])\t Attacker Reward : tensor([-4.4514])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 17⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 85 \t Beacon Reward : tensor([5.8757])\t Attacker Reward : tensor([-4.1243])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 18⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 90 \t Beacon Reward : tensor([5.6466])\t Attacker Reward : tensor([-4.3534])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 19⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 95 \t Beacon Reward : tensor([6.0011])\t Attacker Reward : tensor([-3.9989])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 20⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 100 \t Beacon Reward : tensor([6.2829])\t Attacker Reward : tensor([-3.7171])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:26\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 21⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 105 \t Beacon Reward : tensor([6.3650])\t Attacker Reward : tensor([-3.6350])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 22⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 110 \t Beacon Reward : tensor([5.6136])\t Attacker Reward : tensor([-4.3864])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 23⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 115 \t Beacon Reward : tensor([5.7714])\t Attacker Reward : tensor([-4.2286])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 24⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 120 \t Beacon Reward : tensor([6.5215])\t Attacker Reward : tensor([-3.4785])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 25⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 125 \t Beacon Reward : tensor([6.2359])\t Attacker Reward : tensor([-3.7641])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 26⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 130 \t Beacon Reward : tensor([7.4509])\t Attacker Reward : tensor([-2.5491])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 27⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 135 \t Beacon Reward : tensor([5.8600])\t Attacker Reward : tensor([-4.1400])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 28⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 140 \t Beacon Reward : tensor([5.9436])\t Attacker Reward : tensor([-4.0564])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 29⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 145 \t Beacon Reward : tensor([6.6560])\t Attacker Reward : tensor([-3.3440])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 30⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 150 \t Beacon Reward : tensor([6.4267])\t Attacker Reward : tensor([-3.5733])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:38\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 31⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 155 \t Beacon Reward : tensor([9.2406])\t Attacker Reward : tensor([-0.7594])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 32⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 160 \t Beacon Reward : tensor([9.4227])\t Attacker Reward : tensor([-0.5773])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 33⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 165 \t Beacon Reward : tensor([9.1837])\t Attacker Reward : tensor([-0.8163])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 34⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 170 \t Beacon Reward : tensor([9.0170])\t Attacker Reward : tensor([-0.9830])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 35⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 175 \t Beacon Reward : tensor([9.5626])\t Attacker Reward : tensor([-0.4374])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 36⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 180 \t Beacon Reward : tensor([8.8810])\t Attacker Reward : tensor([-1.1190])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 37⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 185 \t Beacon Reward : tensor([9.1435])\t Attacker Reward : tensor([-0.8565])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 38⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 190 \t Beacon Reward : tensor([9.3551])\t Attacker Reward : tensor([-0.6449])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 39⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 195 \t Beacon Reward : tensor([9.5160])\t Attacker Reward : tensor([-0.4840])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 40⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 200 \t Beacon Reward : tensor([9.6596])\t Attacker Reward : tensor([-0.3404])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:51\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 41⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 205 \t Beacon Reward : tensor([9.0333])\t Attacker Reward : tensor([-0.9667])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 42⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 210 \t Beacon Reward : tensor([9.4170])\t Attacker Reward : tensor([-0.5830])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 43⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 215 \t Beacon Reward : tensor([9.6929])\t Attacker Reward : tensor([-0.3071])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 44⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 220 \t Beacon Reward : tensor([9.2865])\t Attacker Reward : tensor([-0.7135])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 45⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 225 \t Beacon Reward : tensor([9.4657])\t Attacker Reward : tensor([-0.5343])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 46⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 2 \t Timestep : 226 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 47⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 231 \t Beacon Reward : tensor([9.1646])\t Attacker Reward : tensor([-0.8354])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 48⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 236 \t Beacon Reward : tensor([9.0262])\t Attacker Reward : tensor([-0.2138])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 49⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 241 \t Beacon Reward : tensor([8.9576])\t Attacker Reward : tensor([-0.2224])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 50⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 246 \t Beacon Reward : tensor([9.7031])\t Attacker Reward : tensor([-0.2969])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:03\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 51⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 251 \t Beacon Reward : tensor([9.6064])\t Attacker Reward : tensor([-0.3936])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 52⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 7 \t Timestep : 252 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 53⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 257 \t Beacon Reward : tensor([9.8693])\t Attacker Reward : tensor([-0.1307])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 54⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 5 \t Timestep : 260 \t Beacon Reward : tensor([-11.6200])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 55⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 2 \t Timestep : 261 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 56⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 5 \t Timestep : 264 \t Beacon Reward : tensor([-11.6200])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 57⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 7 \t Timestep : 265 \t Beacon Reward : tensor([-14.0358])\t Attacker Reward : tensor([39.9442])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 58⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 2 \t Timestep : 266 \t Beacon Reward : tensor([-14.0515])\t Attacker Reward : tensor([39.9085])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 59⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 271 \t Beacon Reward : tensor([9.3871])\t Attacker Reward : tensor([-0.6129])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 60⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 276 \t Beacon Reward : tensor([9.6455])\t Attacker Reward : tensor([-0.3545])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:10\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 61⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 7 \t Timestep : 277 \t Beacon Reward : tensor([-14.0330])\t Attacker Reward : tensor([39.9470])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 62⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 4 \t Timestep : 278 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 63⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 0 \t Timestep : 279 \t Beacon Reward : tensor([-14.])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 64⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 1 \t Timestep : 281 \t Beacon Reward : tensor([-12.9200])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 65⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 286 \t Beacon Reward : tensor([6.6045])\t Attacker Reward : tensor([-0.2155])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 66⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 4 \t Timestep : 287 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 67⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 0 \t Timestep : 288 \t Beacon Reward : tensor([-14.1546])\t Attacker Reward : tensor([39.8454])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 68⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 293 \t Beacon Reward : tensor([9.4278])\t Attacker Reward : tensor([-0.5722])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 69⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 5 \t Timestep : 296 \t Beacon Reward : tensor([-11.6200])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 70⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 301 \t Beacon Reward : tensor([9.7916])\t Attacker Reward : tensor([-0.2084])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:17\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 71⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 306 \t Beacon Reward : tensor([9.6466])\t Attacker Reward : tensor([-0.3534])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 72⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 0 \t Timestep : 307 \t Beacon Reward : tensor([-14.])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 73⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 6 \t Timestep : 308 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 74⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 6 \t Timestep : 309 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 75⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 314 \t Beacon Reward : tensor([9.5715])\t Attacker Reward : tensor([-0.4285])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 76⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 4 \t Timestep : 315 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 77⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 7 \t Timestep : 316 \t Beacon Reward : tensor([-14.0092])\t Attacker Reward : tensor([39.9708])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 78⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 321 \t Beacon Reward : tensor([9.5303])\t Attacker Reward : tensor([-0.4697])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 79⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 6 \t Timestep : 322 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 80⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 327 \t Beacon Reward : tensor([9.3255])\t Attacker Reward : tensor([-0.6745])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:24\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 81⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 332 \t Beacon Reward : tensor([9.6128])\t Attacker Reward : tensor([-0.3872])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 82⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 337 \t Beacon Reward : tensor([8.7529])\t Attacker Reward : tensor([-0.3271])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 83⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 342 \t Beacon Reward : tensor([9.4819])\t Attacker Reward : tensor([-0.5181])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 84⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 347 \t Beacon Reward : tensor([9.6380])\t Attacker Reward : tensor([-0.3620])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 85⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 4 \t Timestep : 348 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 86⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 353 \t Beacon Reward : tensor([9.8984])\t Attacker Reward : tensor([-0.1016])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 87⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 358 \t Beacon Reward : tensor([9.4908])\t Attacker Reward : tensor([-0.5092])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 88⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 3 \t Timestep : 360 \t Beacon Reward : tensor([-12.8000])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 89⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 365 \t Beacon Reward : tensor([9.7441])\t Attacker Reward : tensor([-0.2559])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 90⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 7 \t Timestep : 366 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:33\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 91⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 371 \t Beacon Reward : tensor([9.7731])\t Attacker Reward : tensor([-0.2269])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 92⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 376 \t Beacon Reward : tensor([9.4318])\t Attacker Reward : tensor([-0.5682])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 93⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 381 \t Beacon Reward : tensor([9.4552])\t Attacker Reward : tensor([-0.5448])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 94⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 386 \t Beacon Reward : tensor([8.5714])\t Attacker Reward : tensor([-0.1286])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 95⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 391 \t Beacon Reward : tensor([8.9080])\t Attacker Reward : tensor([-0.2720])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 96⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 6 \t Timestep : 392 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 97⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 397 \t Beacon Reward : tensor([9.6025])\t Attacker Reward : tensor([-0.3975])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 98⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 0 \t Timestep : 398 \t Beacon Reward : tensor([-14.1003])\t Attacker Reward : tensor([39.8997])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 99⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 403 \t Beacon Reward : tensor([9.7828])\t Attacker Reward : tensor([-0.2173])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 100⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 408 \t Beacon Reward : tensor([9.4833])\t Attacker Reward : tensor([-0.5167])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:44\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 101⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 413 \t Beacon Reward : tensor([9.4829])\t Attacker Reward : tensor([-0.5171])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 102⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 6 \t Timestep : 414 \t Beacon Reward : tensor([-13.9650])\t Attacker Reward : tensor([39.9950])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 103⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 2 \t Timestep : 415 \t Beacon Reward : tensor([-13.9764])\t Attacker Reward : tensor([39.9836])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 104⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 2 \t Timestep : 416 \t Beacon Reward : tensor([-13.9600])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 105⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 421 \t Beacon Reward : tensor([9.6476])\t Attacker Reward : tensor([-0.3524])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 106⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 426 \t Beacon Reward : tensor([8.6447])\t Attacker Reward : tensor([-0.5353])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 107⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 431 \t Beacon Reward : tensor([9.1369])\t Attacker Reward : tensor([-0.8631])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 108⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "⛔⛔⛔ Attacker Identified the VICTIM ⛔⛔⛔\n",
      "Victim: 7 \t Timestep : 432 \t Beacon Reward : tensor([-13.9800])\t Attacker Reward : tensor([40.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 109⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 437 \t Beacon Reward : tensor([9.2764])\t Attacker Reward : tensor([-0.7236])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 110⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 442 \t Beacon Reward : tensor([9.2878])\t Attacker Reward : tensor([-0.7122])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:53\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 111⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 447 \t Beacon Reward : tensor([8.7140])\t Attacker Reward : tensor([-1.2860])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 112⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 452 \t Beacon Reward : tensor([9.0515])\t Attacker Reward : tensor([-0.9485])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 113⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 457 \t Beacon Reward : tensor([9.2504])\t Attacker Reward : tensor([-0.7496])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 114⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 462 \t Beacon Reward : tensor([8.9466])\t Attacker Reward : tensor([-1.0534])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 115⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 467 \t Beacon Reward : tensor([9.3803])\t Attacker Reward : tensor([-0.6197])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 116⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 472 \t Beacon Reward : tensor([9.0318])\t Attacker Reward : tensor([-0.9682])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 117⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 477 \t Beacon Reward : tensor([9.2848])\t Attacker Reward : tensor([-0.7152])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 118⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 482 \t Beacon Reward : tensor([9.4613])\t Attacker Reward : tensor([-0.5387])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 119⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 487 \t Beacon Reward : tensor([9.1692])\t Attacker Reward : tensor([-0.8308])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 120⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 492 \t Beacon Reward : tensor([9.2528])\t Attacker Reward : tensor([-0.7471])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:02:06\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 121⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 497 \t Beacon Reward : tensor([8.9961])\t Attacker Reward : tensor([-1.0039])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 122⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 502 \t Beacon Reward : tensor([9.1501])\t Attacker Reward : tensor([-0.8499])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 123⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 507 \t Beacon Reward : tensor([8.8057])\t Attacker Reward : tensor([-1.1943])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 124⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 512 \t Beacon Reward : tensor([8.4780])\t Attacker Reward : tensor([-1.5220])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 125⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 517 \t Beacon Reward : tensor([9.0478])\t Attacker Reward : tensor([-0.9522])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 126⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 522 \t Beacon Reward : tensor([8.8627])\t Attacker Reward : tensor([-1.1373])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 127⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 527 \t Beacon Reward : tensor([8.6523])\t Attacker Reward : tensor([-1.3477])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 128⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 532 \t Beacon Reward : tensor([9.0584])\t Attacker Reward : tensor([-0.9416])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 129⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 537 \t Beacon Reward : tensor([9.0120])\t Attacker Reward : tensor([-0.9880])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 130⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 542 \t Beacon Reward : tensor([8.6776])\t Attacker Reward : tensor([-1.3224])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:02:18\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 131⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 547 \t Beacon Reward : tensor([8.8377])\t Attacker Reward : tensor([-1.1623])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 132⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 552 \t Beacon Reward : tensor([9.0391])\t Attacker Reward : tensor([-0.9609])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 133⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 557 \t Beacon Reward : tensor([9.0378])\t Attacker Reward : tensor([-0.9622])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 134⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 562 \t Beacon Reward : tensor([8.7648])\t Attacker Reward : tensor([-1.2352])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 135⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 567 \t Beacon Reward : tensor([8.9449])\t Attacker Reward : tensor([-1.0551])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 136⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 572 \t Beacon Reward : tensor([8.6043])\t Attacker Reward : tensor([-1.3957])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 137⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 577 \t Beacon Reward : tensor([8.5963])\t Attacker Reward : tensor([-1.4037])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 138⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 582 \t Beacon Reward : tensor([9.0306])\t Attacker Reward : tensor([-0.9694])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 139⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 587 \t Beacon Reward : tensor([8.7526])\t Attacker Reward : tensor([-1.2474])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 140⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 592 \t Beacon Reward : tensor([8.7003])\t Attacker Reward : tensor([-1.2997])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:02:31\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 141⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 597 \t Beacon Reward : tensor([8.3706])\t Attacker Reward : tensor([-1.6294])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 142⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 602 \t Beacon Reward : tensor([8.5185])\t Attacker Reward : tensor([-1.4815])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 143⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 607 \t Beacon Reward : tensor([8.8625])\t Attacker Reward : tensor([-1.1375])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 144⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 612 \t Beacon Reward : tensor([8.6549])\t Attacker Reward : tensor([-1.3451])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 145⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 617 \t Beacon Reward : tensor([8.8411])\t Attacker Reward : tensor([-1.1589])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 146⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 622 \t Beacon Reward : tensor([8.9367])\t Attacker Reward : tensor([-1.0633])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 147⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 627 \t Beacon Reward : tensor([8.7320])\t Attacker Reward : tensor([-1.2680])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 148⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 632 \t Beacon Reward : tensor([8.9832])\t Attacker Reward : tensor([-1.0168])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 149⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 637 \t Beacon Reward : tensor([8.7177])\t Attacker Reward : tensor([-1.2823])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 150⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 642 \t Beacon Reward : tensor([8.8174])\t Attacker Reward : tensor([-1.1826])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:02:44\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 151⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 647 \t Beacon Reward : tensor([8.7093])\t Attacker Reward : tensor([-1.2907])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 152⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 652 \t Beacon Reward : tensor([9.0241])\t Attacker Reward : tensor([-0.9759])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 153⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 657 \t Beacon Reward : tensor([9.0415])\t Attacker Reward : tensor([-0.9585])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 154⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 662 \t Beacon Reward : tensor([8.8077])\t Attacker Reward : tensor([-1.1923])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 155⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 667 \t Beacon Reward : tensor([8.7386])\t Attacker Reward : tensor([-1.2614])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 156⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 672 \t Beacon Reward : tensor([8.9192])\t Attacker Reward : tensor([-1.0808])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 157⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 677 \t Beacon Reward : tensor([8.6278])\t Attacker Reward : tensor([-1.3722])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 158⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 682 \t Beacon Reward : tensor([8.6847])\t Attacker Reward : tensor([-1.3153])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 159⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 687 \t Beacon Reward : tensor([8.8049])\t Attacker Reward : tensor([-1.1951])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 160⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 692 \t Beacon Reward : tensor([9.2046])\t Attacker Reward : tensor([-0.7954])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:02:56\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 161⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 697 \t Beacon Reward : tensor([8.6622])\t Attacker Reward : tensor([-1.3378])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 162⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 702 \t Beacon Reward : tensor([8.6563])\t Attacker Reward : tensor([-1.3437])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 163⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 707 \t Beacon Reward : tensor([8.9622])\t Attacker Reward : tensor([-1.0378])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 164⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 712 \t Beacon Reward : tensor([8.5752])\t Attacker Reward : tensor([-1.4248])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 165⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 717 \t Beacon Reward : tensor([8.8421])\t Attacker Reward : tensor([-1.1579])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 166⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 722 \t Beacon Reward : tensor([8.8432])\t Attacker Reward : tensor([-1.1568])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 167⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 727 \t Beacon Reward : tensor([9.0234])\t Attacker Reward : tensor([-0.9766])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 168⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 732 \t Beacon Reward : tensor([8.8011])\t Attacker Reward : tensor([-1.1989])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 169⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 737 \t Beacon Reward : tensor([8.6169])\t Attacker Reward : tensor([-1.3831])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 170⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 742 \t Beacon Reward : tensor([8.7554])\t Attacker Reward : tensor([-1.2446])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:03:09\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 171⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 747 \t Beacon Reward : tensor([8.6416])\t Attacker Reward : tensor([-1.3584])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 172⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 752 \t Beacon Reward : tensor([9.0073])\t Attacker Reward : tensor([-0.9927])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 173⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 757 \t Beacon Reward : tensor([8.6905])\t Attacker Reward : tensor([-1.3095])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 174⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 762 \t Beacon Reward : tensor([8.7472])\t Attacker Reward : tensor([-1.2528])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 175⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 767 \t Beacon Reward : tensor([8.4710])\t Attacker Reward : tensor([-1.5290])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 176⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 772 \t Beacon Reward : tensor([9.1635])\t Attacker Reward : tensor([-0.8365])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 177⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 777 \t Beacon Reward : tensor([8.5558])\t Attacker Reward : tensor([-1.4442])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 178⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 782 \t Beacon Reward : tensor([8.2724])\t Attacker Reward : tensor([-1.7276])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 179⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 787 \t Beacon Reward : tensor([8.6701])\t Attacker Reward : tensor([-1.3299])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 180⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 792 \t Beacon Reward : tensor([8.7802])\t Attacker Reward : tensor([-1.2198])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:03:22\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 181⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 797 \t Beacon Reward : tensor([9.1405])\t Attacker Reward : tensor([-0.8595])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 182⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 802 \t Beacon Reward : tensor([8.4679])\t Attacker Reward : tensor([-1.5321])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 183⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 807 \t Beacon Reward : tensor([8.7404])\t Attacker Reward : tensor([-1.2596])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 184⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 812 \t Beacon Reward : tensor([8.9419])\t Attacker Reward : tensor([-1.0581])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 185⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 817 \t Beacon Reward : tensor([8.6854])\t Attacker Reward : tensor([-1.3146])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 186⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 822 \t Beacon Reward : tensor([8.5370])\t Attacker Reward : tensor([-1.4630])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 187⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 827 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 188⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 832 \t Beacon Reward : tensor([8.9517])\t Attacker Reward : tensor([-1.0483])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 189⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 837 \t Beacon Reward : tensor([8.7876])\t Attacker Reward : tensor([-1.2124])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 190⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 842 \t Beacon Reward : tensor([8.6762])\t Attacker Reward : tensor([-1.3238])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:03:34\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 191⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 847 \t Beacon Reward : tensor([8.8803])\t Attacker Reward : tensor([-1.1197])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 192⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 852 \t Beacon Reward : tensor([8.8606])\t Attacker Reward : tensor([-1.1394])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 193⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 857 \t Beacon Reward : tensor([8.7007])\t Attacker Reward : tensor([-1.2993])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 194⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 862 \t Beacon Reward : tensor([8.6986])\t Attacker Reward : tensor([-1.3014])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 195⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 867 \t Beacon Reward : tensor([8.7515])\t Attacker Reward : tensor([-1.2485])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 196⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 872 \t Beacon Reward : tensor([8.8797])\t Attacker Reward : tensor([-1.1203])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 197⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 877 \t Beacon Reward : tensor([8.8099])\t Attacker Reward : tensor([-1.1901])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 198⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 882 \t Beacon Reward : tensor([8.5381])\t Attacker Reward : tensor([-1.4619])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 199⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 887 \t Beacon Reward : tensor([8.4290])\t Attacker Reward : tensor([-1.5710])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 200⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 892 \t Beacon Reward : tensor([8.9758])\t Attacker Reward : tensor([-1.0242])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:03:47\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 201⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 897 \t Beacon Reward : tensor([8.7034])\t Attacker Reward : tensor([-1.2966])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 202⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 902 \t Beacon Reward : tensor([8.7044])\t Attacker Reward : tensor([-1.2956])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 203⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 907 \t Beacon Reward : tensor([8.8079])\t Attacker Reward : tensor([-1.1921])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 204⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 912 \t Beacon Reward : tensor([8.9055])\t Attacker Reward : tensor([-1.0945])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 205⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 917 \t Beacon Reward : tensor([8.9185])\t Attacker Reward : tensor([-1.0815])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 206⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 922 \t Beacon Reward : tensor([8.8630])\t Attacker Reward : tensor([-1.1370])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 207⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 927 \t Beacon Reward : tensor([8.8506])\t Attacker Reward : tensor([-1.1494])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 208⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 932 \t Beacon Reward : tensor([9.2856])\t Attacker Reward : tensor([-0.7144])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 209⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 937 \t Beacon Reward : tensor([9.1308])\t Attacker Reward : tensor([-0.8692])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 210⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 942 \t Beacon Reward : tensor([8.9987])\t Attacker Reward : tensor([-1.0013])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:00\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 211⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 947 \t Beacon Reward : tensor([8.6768])\t Attacker Reward : tensor([-1.3232])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 212⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 952 \t Beacon Reward : tensor([8.7666])\t Attacker Reward : tensor([-1.2334])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 213⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 957 \t Beacon Reward : tensor([8.7392])\t Attacker Reward : tensor([-1.2608])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 214⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 962 \t Beacon Reward : tensor([8.8181])\t Attacker Reward : tensor([-1.1819])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 215⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 967 \t Beacon Reward : tensor([8.5732])\t Attacker Reward : tensor([-1.4268])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 216⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 972 \t Beacon Reward : tensor([8.6061])\t Attacker Reward : tensor([-1.3939])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 217⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 977 \t Beacon Reward : tensor([8.9501])\t Attacker Reward : tensor([-1.0499])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 218⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 982 \t Beacon Reward : tensor([8.8673])\t Attacker Reward : tensor([-1.1327])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 219⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 987 \t Beacon Reward : tensor([8.8207])\t Attacker Reward : tensor([-1.1793])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 220⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 992 \t Beacon Reward : tensor([8.9819])\t Attacker Reward : tensor([-1.0181])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:13\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 221⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 997 \t Beacon Reward : tensor([8.7271])\t Attacker Reward : tensor([-1.2729])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 222⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1002 \t Beacon Reward : tensor([8.6345])\t Attacker Reward : tensor([-1.3655])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 223⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1007 \t Beacon Reward : tensor([8.7871])\t Attacker Reward : tensor([-1.2129])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 224⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1012 \t Beacon Reward : tensor([8.8739])\t Attacker Reward : tensor([-1.1261])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 225⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1017 \t Beacon Reward : tensor([8.8751])\t Attacker Reward : tensor([-1.1249])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 226⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1022 \t Beacon Reward : tensor([8.8127])\t Attacker Reward : tensor([-1.1873])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 227⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1027 \t Beacon Reward : tensor([8.6951])\t Attacker Reward : tensor([-1.3049])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 228⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1032 \t Beacon Reward : tensor([8.7141])\t Attacker Reward : tensor([-1.2859])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 229⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1037 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 230⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1042 \t Beacon Reward : tensor([8.8828])\t Attacker Reward : tensor([-1.1172])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:26\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 231⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1047 \t Beacon Reward : tensor([8.6789])\t Attacker Reward : tensor([-1.3211])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 232⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1052 \t Beacon Reward : tensor([8.7377])\t Attacker Reward : tensor([-1.2623])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 233⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1057 \t Beacon Reward : tensor([8.4248])\t Attacker Reward : tensor([-1.5752])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 234⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1062 \t Beacon Reward : tensor([8.7633])\t Attacker Reward : tensor([-1.2367])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 235⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1067 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 236⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1072 \t Beacon Reward : tensor([9.0337])\t Attacker Reward : tensor([-0.9663])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 237⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1077 \t Beacon Reward : tensor([8.8057])\t Attacker Reward : tensor([-1.1943])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 238⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1082 \t Beacon Reward : tensor([8.8005])\t Attacker Reward : tensor([-1.1995])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 239⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1087 \t Beacon Reward : tensor([8.6441])\t Attacker Reward : tensor([-1.3559])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 240⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1092 \t Beacon Reward : tensor([8.8770])\t Attacker Reward : tensor([-1.1230])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:38\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 241⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1097 \t Beacon Reward : tensor([8.7164])\t Attacker Reward : tensor([-1.2836])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 242⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1102 \t Beacon Reward : tensor([9.0280])\t Attacker Reward : tensor([-0.9720])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 243⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1107 \t Beacon Reward : tensor([8.9903])\t Attacker Reward : tensor([-1.0097])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 244⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1112 \t Beacon Reward : tensor([8.6259])\t Attacker Reward : tensor([-1.3741])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 245⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1117 \t Beacon Reward : tensor([8.7733])\t Attacker Reward : tensor([-1.2267])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 246⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1122 \t Beacon Reward : tensor([9.1241])\t Attacker Reward : tensor([-0.8759])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 247⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1127 \t Beacon Reward : tensor([8.8342])\t Attacker Reward : tensor([-1.1658])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 248⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1132 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 249⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1137 \t Beacon Reward : tensor([8.9464])\t Attacker Reward : tensor([-1.0536])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 250⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 1142 \t Beacon Reward : tensor([8.6217])\t Attacker Reward : tensor([-1.3783])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:04:51\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 251⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1147 \t Beacon Reward : tensor([9.1972])\t Attacker Reward : tensor([-0.8028])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 252⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1152 \t Beacon Reward : tensor([8.5659])\t Attacker Reward : tensor([-1.4341])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 253⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1157 \t Beacon Reward : tensor([8.9577])\t Attacker Reward : tensor([-1.0423])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 254⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1162 \t Beacon Reward : tensor([8.6492])\t Attacker Reward : tensor([-1.3508])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 255⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1167 \t Beacon Reward : tensor([9.1650])\t Attacker Reward : tensor([-0.8350])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 256⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1172 \t Beacon Reward : tensor([9.0332])\t Attacker Reward : tensor([-0.9668])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 257⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1177 \t Beacon Reward : tensor([8.8865])\t Attacker Reward : tensor([-1.1135])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 258⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1182 \t Beacon Reward : tensor([8.8062])\t Attacker Reward : tensor([-1.1938])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 259⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1187 \t Beacon Reward : tensor([8.8674])\t Attacker Reward : tensor([-1.1326])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 260⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1192 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:05:04\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 261⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 2 \t Timestep : 1197 \t Beacon Reward : tensor([9.0471])\t Attacker Reward : tensor([-0.9529])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 262⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1202 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 263⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1207 \t Beacon Reward : tensor([8.6683])\t Attacker Reward : tensor([-1.3317])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 264⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1212 \t Beacon Reward : tensor([9.0632])\t Attacker Reward : tensor([-0.9368])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 265⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1217 \t Beacon Reward : tensor([8.8090])\t Attacker Reward : tensor([-1.1910])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 266⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1222 \t Beacon Reward : tensor([8.9492])\t Attacker Reward : tensor([-1.0508])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 267⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1227 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 268⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1232 \t Beacon Reward : tensor([8.6851])\t Attacker Reward : tensor([-1.3149])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 269⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1237 \t Beacon Reward : tensor([8.9706])\t Attacker Reward : tensor([-1.0294])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 270⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1242 \t Beacon Reward : tensor([8.7812])\t Attacker Reward : tensor([-1.2188])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:05:17\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 271⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1247 \t Beacon Reward : tensor([8.6003])\t Attacker Reward : tensor([-1.3997])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 272⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1252 \t Beacon Reward : tensor([8.8927])\t Attacker Reward : tensor([-1.1073])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 273⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1257 \t Beacon Reward : tensor([8.8346])\t Attacker Reward : tensor([-1.1654])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 274⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1262 \t Beacon Reward : tensor([8.7073])\t Attacker Reward : tensor([-1.2927])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 275⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1267 \t Beacon Reward : tensor([8.8758])\t Attacker Reward : tensor([-1.1242])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 276⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1272 \t Beacon Reward : tensor([8.9360])\t Attacker Reward : tensor([-1.0640])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 277⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1277 \t Beacon Reward : tensor([8.7183])\t Attacker Reward : tensor([-1.2817])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 278⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1282 \t Beacon Reward : tensor([8.9248])\t Attacker Reward : tensor([-1.0752])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 279⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1287 \t Beacon Reward : tensor([8.6266])\t Attacker Reward : tensor([-1.3734])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 280⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1292 \t Beacon Reward : tensor([8.7677])\t Attacker Reward : tensor([-1.2323])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:05:29\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 281⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1297 \t Beacon Reward : tensor([8.9761])\t Attacker Reward : tensor([-1.0239])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 282⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1302 \t Beacon Reward : tensor([8.6481])\t Attacker Reward : tensor([-1.3519])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 283⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1307 \t Beacon Reward : tensor([8.5245])\t Attacker Reward : tensor([-1.4755])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 284⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1312 \t Beacon Reward : tensor([8.9750])\t Attacker Reward : tensor([-1.0250])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 285⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1317 \t Beacon Reward : tensor([8.4128])\t Attacker Reward : tensor([-1.5872])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 286⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 4 \t Timestep : 1322 \t Beacon Reward : tensor([8.5218])\t Attacker Reward : tensor([-1.4782])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 287⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 6 \t Timestep : 1327 \t Beacon Reward : tensor([8.6540])\t Attacker Reward : tensor([-1.3460])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 288⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1332 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 289⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1337 \t Beacon Reward : tensor([8.9934])\t Attacker Reward : tensor([-1.0066])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 290⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 9 \t Timestep : 1342 \t Beacon Reward : tensor([8.8529])\t Attacker Reward : tensor([-1.1471])\n",
      "--------------------------------------------------------------------------------------------\n",
      "updating the agent\n",
      "saving model at : ./results/train/run5/weights/PPO_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:05:42\n",
      "--------------------------------------------------------------------------------------------\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 291⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 3 \t Timestep : 1347 \t Beacon Reward : tensor([9.])\t Attacker Reward : tensor([-1.])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 292⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1352 \t Beacon Reward : tensor([8.7196])\t Attacker Reward : tensor([-1.2804])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 293⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1357 \t Beacon Reward : tensor([8.9055])\t Attacker Reward : tensor([-1.0945])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 294⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1362 \t Beacon Reward : tensor([8.9926])\t Attacker Reward : tensor([-1.0074])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 295⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 5 \t Timestep : 1367 \t Beacon Reward : tensor([9.1909])\t Attacker Reward : tensor([-0.8091])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 296⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 7 \t Timestep : 1372 \t Beacon Reward : tensor([8.5519])\t Attacker Reward : tensor([-1.4481])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 297⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 1 \t Timestep : 1377 \t Beacon Reward : tensor([8.6230])\t Attacker Reward : tensor([-1.3770])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 298⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 0 \t Timestep : 1382 \t Beacon Reward : tensor([8.8662])\t Attacker Reward : tensor([-1.1338])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 299⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n",
      "✅✅✅ Attacker Could NOT Indentify the VICTIM ✅✅✅\n",
      "Victim: 8 \t Timestep : 1387 \t Beacon Reward : tensor([8.9722])\t Attacker Reward : tensor([-1.0278])\n",
      "==================================⬇️⬇️⬇️⬇️Episode: 300⬇️⬇️⬇️⬇️==============================\n",
      "-------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 92\u001b[0m\n\u001b[1;32m     87\u001b[0m         train_both(args, env, beacon_agent, attacker_agent)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# with open(args.results_dir + '/output.txt', 'w') as sys.stdout:\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 26\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     action_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \n\u001b[1;32m     25\u001b[0m     beacon_agent \u001b[38;5;241m=\u001b[39m TD3(state_dim, action_dim, max_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mtrain_TD_beacon\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeacon_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mbeacon_agent \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     29\u001b[0m     K_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m         \u001b[38;5;66;03m# update policy for K epochs\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sobhan/Beacons/engine.py:293\u001b[0m, in \u001b[0;36mtrain_TD_beacon\u001b[0;34m(args, env, ppo_agent, attacker_agent)\u001b[0m\n\u001b[1;32m    291\u001b[0m current_ep_areward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mmax_queries\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     binfo, rewards, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeacon_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mppo_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacker_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattacker_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     beacon_reward \u001b[38;5;241m=\u001b[39m rewards[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    297\u001b[0m     current_ep_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m beacon_reward\n",
      "File \u001b[0;32m/mnt/sobhan/Beacons/env.py:189\u001b[0m, in \u001b[0;36mEnv.step\u001b[0;34m(self, beacon_agent, attacker_agent)\u001b[0m\n\u001b[1;32m    186\u001b[0m log_env(info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeacon\u001b[38;5;241m.\u001b[39mcontrol_info, episode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, log_env_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_beacon_control)\n\u001b[1;32m    188\u001b[0m log_victim(info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattacker\u001b[38;5;241m.\u001b[39mvictim_info, episode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, log_env_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_attacker)\n\u001b[0;32m--> 189\u001b[0m \u001b[43mlog_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepisode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_env_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_attacker_control\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeacon\u001b[38;5;241m.\u001b[39mget_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattacker_action)\n",
      "File \u001b[0;32m/mnt/sobhan/Beacons/utils.py:103\u001b[0m, in \u001b[0;36mlog_env\u001b[0;34m(info, episode, step, log_env_name)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gene_idx, gene_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(beacon_data):\n\u001b[1;32m    102\u001b[0m         snp, maf, res, current, lrts \u001b[38;5;241m=\u001b[39m gene_data\n\u001b[0;32m--> 103\u001b[0m         log_env_writer\u001b[38;5;241m.\u001b[39mwriterow([episode, step, beacon_idx, gene_idx, \u001b[43msnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), maf\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), res\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), lrts\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()])\n\u001b[1;32m    104\u001b[0m log_env_writer\u001b[38;5;241m.\u001b[39mwriterow([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from env import Env\n",
    "from ppo import PPO\n",
    "from ddpg import DDPG\n",
    "from td import TD3\n",
    "from engine import train_beacon, train_attacker, train_both, train_TD_beacon\n",
    "\n",
    "args = args_create()\n",
    "def main():\n",
    "    env = Env(args, beacon, maf_values, binary)\n",
    "    \n",
    "    if args.train == \"beacon\":\n",
    "        ################ PPO hyperparameters ################\n",
    "        if args.resume_attacker:\n",
    "            attacker_agent = PPO(400, 10, lr_actor, lr_critic, gamma, K_epochs, eps_clip, False, None)\n",
    "            attacker_agent.load(args.resume_attacker)\n",
    "\n",
    "\n",
    "        if args.beacon_agent == \"td\":\n",
    "            state_dim = 9\n",
    "            action_dim = 1  \n",
    "            beacon_agent = TD3(state_dim, action_dim, max_action=1)\n",
    "            train_TD_beacon(args, env, beacon_agent)\n",
    "\n",
    "        elif args.beacon_agent == \"ppo\":\n",
    "            K_epochs = 300         # update policy for K epochs\n",
    "            eps_clip = 0.2           # clip parameter for PPO\n",
    "            gamma = 0.99                # discount factor\n",
    "\n",
    "            lr_actor = 0.001       # learning rate for actor network\n",
    "            lr_critic = 0.001        # learning rate for critic network\n",
    "\n",
    "            beacon_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, False, None)\n",
    "            train_beacon(args, env, beacon_agent)\n",
    "\n",
    "        else:\n",
    "            raise NotImplemented\n",
    "            \n",
    "            \n",
    "    elif args.train == \"attacker\":\n",
    "        attacker_state_dim = 400\n",
    "        attacker_action_dim = 10\n",
    "\n",
    "        ################ PPO hyperparameters ################\n",
    "        K_epochs = 300         # update policy for K epochs\n",
    "        eps_clip = 0.2           # clip parameter for PPO\n",
    "        gamma = 0.99                # discount factor\n",
    "\n",
    "        lr_actor = 0.001       # learning rate for actor network\n",
    "        lr_critic = 0.001        # learning rate for critic network\n",
    "\n",
    "        attacker_agent = PPO(attacker_state_dim, attacker_action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, False, None)\n",
    "        train_attacker(args, env, attacker_agent)\n",
    "\n",
    "    else:\n",
    "        ################ PPO hyperparameters ################\n",
    "        K_epochs = 300         # update policy for K epochs\n",
    "        eps_clip = 0.2           # clip parameter for PPO\n",
    "        gamma = 0.99                # discount factor\n",
    "\n",
    "        lr_actor = 0.0001       # learning rate for actor network\n",
    "        lr_critic = 0.0001        # learning rate for critic network\n",
    "\n",
    "        action_std = 0.4\n",
    "\n",
    "        state_dim = 9\n",
    "        action_dim = 1\n",
    "\n",
    "        attacker_state_dim = 400\n",
    "        attacker_action_dim = 10\n",
    "\n",
    "        # initialize a PPO agent\n",
    "        # beacon_agent = DDPG(state_dim, action_dim, )\n",
    "        beacon_agent = TD3(state_dim, action_dim, max_action=1)\n",
    "        # beacon_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, False, None)\n",
    "        attacker_agent = PPO(attacker_state_dim, attacker_action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, False, None)\n",
    "\n",
    "        if args.resume_attacker:\n",
    "            attacker_agent.load(args.resume_attacker)\n",
    "\n",
    "        if args.resume_beacon:\n",
    "            beacon_agent.load(args.resume_beacon)\n",
    "            \n",
    "        train_both(args, env, beacon_agent, attacker_agent)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # with open(args.results_dir + '/output.txt', 'w') as sys.stdout:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr_list = []\n",
    "model = [torch.nn.Parameter(torch.randn(2, 2, requires_grad=True))]\n",
    "\n",
    "# Initial learning rate\n",
    "LR = 0.001\n",
    "optimizer = torch.optim.Adam(model, lr=LR)\n",
    "\n",
    "# Define the CyclicLR scheduler\n",
    "max_lr = 0.01\n",
    "min_lr = 0.000001\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "    optimizer, base_lr=0.00001, max_lr=0.01, \n",
    "    cycle_momentum=False, mode='triangular2', step_size_up=5, step_size_down=5\n",
    ")\n",
    "\n",
    "# Simulate training over multiple epochs\n",
    "for epoch in range(1, 5):\n",
    "    data_size = 200\n",
    "    for i in range(data_size):\n",
    "        optimizer.zero_grad()\n",
    "        # Simulate a step (e.g., loss.backward() and optimizer.step())\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record the current learning rate\n",
    "        lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "# Plot the learning rate schedule\n",
    "plt.plot(range(len(lr_list)), lr_list, color='r')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('CyclicLR Schedule')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.3652)\n"
     ]
    }
   ],
   "source": [
    "genome = torch.as_tensor(1)\n",
    "maf =   torch.as_tensor(0.1790)\n",
    "response =  torch.as_tensor(1)\n",
    "\n",
    "\n",
    "DN_i = (1 - maf).pow(2 * 3) \n",
    "DN_i_1 = (1 - maf).pow(2 * 3 - 2)\n",
    "\n",
    "# Genome == 1\n",
    "log1 = torch.log(DN_i) - torch.log(0.001 * DN_i_1)\n",
    "log2 = torch.log((0.001 * DN_i_1 * (1 - DN_i))) - torch.log(DN_i * (1 - 0.001 * DN_i_1))\n",
    "\n",
    "# Genome == 0\n",
    "log3 = torch.log(DN_i) - torch.log((1 - 0.001) * DN_i_1)\n",
    "log4 = torch.log((1 - 0.001) * DN_i_1 * (1 - DN_i)) - torch.log(DN_i * (1 - DN_i_1 * (1 - 0.001)))\n",
    "\n",
    "x_hat_i = (genome * response) + ((1 - genome) * (1 - response))\n",
    "lrt = (log1 + log2 * x_hat_i)* genome + (log3 + log4 * x_hat_i) * (1 - genome)\n",
    "        # print(\"lrts, lrts.size()\", lrts, lrts.size())\n",
    "print(lrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1669"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0991 + 0.0678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
